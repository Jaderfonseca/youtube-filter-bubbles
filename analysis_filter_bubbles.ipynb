{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jaderfonseca/youtube-filter-bubbles/blob/main/analysis_filter_bubbles.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ef5a487b"
      },
      "source": [
        "# Exploring Filter Bubbles in YouTube Recommendations\n",
        "**Mini‑project** · Portfolio-ready version\n",
        "\n",
        "This notebook reproduces the pipeline used to collect a small corpus of YouTube videos by seed queries, build a similarity graph via TF‑IDF, cluster content, and compute simple diversity metrics. It is intentionally compact and reproducible for reviewers.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72ea0206"
      },
      "source": [
        "## How to run\n",
        "1. Open in Google Colab.\n",
        "2. Run the **Setup** cell to install packages and securely input your **YouTube Data API v3** key.\n",
        "3. Execute cells in order: **Data collection → Preprocessing → TF‑IDF & Similarity → Clustering → Metrics → Plots**.\n",
        "4. Outputs are written to `data/` and figures to `figures/`.\n",
        "\n",
        "> **Note on consistency across runs.** Re-running the pipeline with fresh API calls changes the exact videos retrieved, but the **structural patterns remain consistent**: near-zero overlap between seeds, siloed clusters per seed, and a rapid reduction of diversity across recommendation steps.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "765002ab"
      },
      "source": [
        "**Folder structure**\n",
        "\n",
        "- `data/raw/` – raw CSVs from collection\n",
        "- `data/clean/` – deduplicated & text‑processed CSVs\n",
        "- `data/processed/` – TF‑IDF, similarity, clustering, metrics\n",
        "- `figures/` – saved plots\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bnK6gainSlF"
      },
      "source": [
        "**YouTube Filter Bubbles — Minimal, Reproducible Pipeline**\n",
        "\n",
        "This notebook loads cleaned CSVs (or optionally collects a small seed set using the YouTube API), builds TF-IDF similarity, constructs a small interpretable graph, and produces four figures:\n",
        "\n",
        "- `figures/graph_overview.png` (network colored by seed, node size by degree)\n",
        "- `figures/graph_lcc.png` (largest connected component)\n",
        "- `figures/jaccard_seeds.png` (Jaccard similarity across seeds)\n",
        "- `figures/diversity_by_seed.png` (normalized entropy)\n",
        "- `figures/entropy_vs_step.png` (entropy vs. graph step)\n",
        "\n",
        "All outputs are written under `data/{raw,clean,processed}` and `figures/`.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q google-api-python-client pandas numpy scikit-learn networkx matplotlib python-louvain\n",
        "\n",
        "import os, json, math, itertools, collections\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "# folders\n",
        "for p in [\"data/raw\",\"data/clean\",\"data/processed\",\"figures\"]:\n",
        "    os.makedirs(p, exist_ok=True)\n",
        "\n",
        "# your three seed topics\n",
        "SEEDS = [\"beginner guitar\", \"healthy cooking\", \"stretching exercises\"]\n",
        "REGION = \"US\"\n",
        "TOPK_PER_SEED = 5          # neighbors per seed when building the small graph\n",
        "RANDOM_STATE = 42\n"
      ],
      "metadata": {
        "id": "YpQNWIZQnjTg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set to True ONLY if you want to recollect data. Otherwise the notebook uses existing CSVs.\n",
        "USE_API = True\n",
        "\n",
        "if USE_API:\n",
        "    from getpass import getpass\n",
        "    from googleapiclient.discovery import build\n",
        "\n",
        "    API_KEY = getpass(\"Paste your YouTube API key (input is hidden): \").strip()\n",
        "    assert API_KEY, \"Empty API_KEY\"\n",
        "\n",
        "    youtube = build(\"youtube\", \"v3\", developerKey=API_KEY, cache_discovery=False)\n",
        "\n",
        "    def search_videos_by_query(query, max_results=150, region_code=\"US\"):\n",
        "        rows, token = [], None\n",
        "        while len(rows) < max_results:\n",
        "            params = dict(part=\"snippet\", q=query, type=\"video\", maxResults=50, regionCode=region_code)\n",
        "            if token: params[\"pageToken\"] = token\n",
        "            r = youtube.search().list(**params).execute()\n",
        "            for it in r.get(\"items\", []):\n",
        "                rows.append({\n",
        "                    \"seed_query\": query,\n",
        "                    \"video_id\": it[\"id\"][\"videoId\"],\n",
        "                    \"title\": it[\"snippet\"].get(\"title\",\"\"),\n",
        "                    \"description\": it[\"snippet\"].get(\"description\",\"\"),\n",
        "                    \"channel_title\": it[\"snippet\"].get(\"channelTitle\",\"\")\n",
        "                })\n",
        "                if len(rows) >= max_results: break\n",
        "            token = r.get(\"nextPageToken\")\n",
        "            if not token: break\n",
        "        return pd.DataFrame(rows)\n",
        "\n",
        "    # collect a small seed set per topic\n",
        "    dfs = [search_videos_by_query(q, max_results=150, region_code=REGION) for q in SEEDS]\n",
        "    df_seed = pd.concat(dfs, ignore_index=True).drop_duplicates(subset=[\"video_id\"])\n",
        "    df_seed.to_csv(\"data/raw/videos_raw.csv\", index=False)\n",
        "    print(\"Saved: data/raw/videos_raw.csv with\", len(df_seed), \"rows\")\n"
      ],
      "metadata": {
        "id": "3UMs1rh-p_pH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load RAW if present, otherwise allow continuing from prior CLEAN\n",
        "nodes_raw = Path(\"data/raw/videos_raw.csv\")\n",
        "if nodes_raw.exists():\n",
        "    df_videos = pd.read_csv(nodes_raw)\n",
        "else:\n",
        "    clean_nodes = Path(\"data/clean/videos_clean.csv\")\n",
        "    assert clean_nodes.exists(), \"No raw or clean nodes available. Enable USE_API once to create data.\"\n",
        "    df_videos = pd.read_csv(clean_nodes)\n",
        "\n",
        "# drop duplicates; drop fully-empty columns\n",
        "df_videos = df_videos.drop_duplicates(subset=[\"video_id\"]).copy()\n",
        "df_videos = df_videos.dropna(axis=1, how=\"all\")\n",
        "\n",
        "# single text field for TF-IDF\n",
        "df_videos[\"text\"] = (df_videos[\"title\"].fillna(\"\") + \" \" + df_videos[\"description\"].fillna(\"\")).str.strip()\n",
        "\n",
        "# save CLEAN nodes\n",
        "df_videos.to_csv(\"data/clean/videos_clean.csv\", index=False)\n",
        "\n",
        "print(\"Saved CLEAN nodes:\", \"data/clean/videos_clean.csv\")\n",
        "print(\"Rows:\", len(df_videos))\n",
        "print(\"Duplicates by video_id:\", df_videos.duplicated(subset=[\"video_id\"]).sum())\n"
      ],
      "metadata": {
        "id": "DcoFklrCqBOr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# TF-IDF\n",
        "vectorizer = TfidfVectorizer(max_features=20000, ngram_range=(1,2), min_df=2)\n",
        "X = vectorizer.fit_transform(df_videos[\"text\"].astype(str))\n",
        "np.save(\"data/processed/tfidf_shape.npy\", np.array(X.shape))\n",
        "\n",
        "# JSON-serializable vocabulary (keys as strings, values as ints)\n",
        "with open(\"data/processed/tfidf_vocabulary.json\",\"w\") as f:\n",
        "    vocab = {str(k): int(v) for k, v in vectorizer.vocabulary_.items()}\n",
        "    json.dump(vocab, f)\n",
        "\n",
        "# cosine similarity (dense OK at this scale)\n",
        "S = cosine_similarity(X)              # N x N\n",
        "np.save(\"data/processed/similarity_matrix.npy\", S)\n",
        "\n",
        "# id -> row index\n",
        "id2idx = {vid:i for i,vid in enumerate(df_videos[\"video_id\"])}\n",
        "\n",
        "# representative seed per video_id\n",
        "seed_per_video = (\n",
        "    df_videos.groupby(\"video_id\")[\"seed_query\"]\n",
        "      .agg(lambda s: s.mode().iloc[0] if not s.mode().empty else \"unknown\")\n",
        "      .to_dict()\n",
        ")\n",
        "\n",
        "# k nearest neighbors excluding self\n",
        "def topk_neighbors(idx, k=TOPK_PER_SEED):\n",
        "    sims = S[idx].copy()\n",
        "    sims[idx] = -1.0\n",
        "    top = np.argsort(-sims)[:k]\n",
        "    return list(zip(top, sims[top]))\n",
        "\n",
        "# build edges by taking k-NN for each video that has one of the target seeds\n",
        "rows = []\n",
        "valid_seed = set(SEEDS)\n",
        "for vid, seed in seed_per_video.items():\n",
        "    if seed not in valid_seed:\n",
        "        continue\n",
        "    i = id2idx.get(vid)\n",
        "    if i is None:\n",
        "        continue\n",
        "    for j, sim in topk_neighbors(i, k=TOPK_PER_SEED):\n",
        "        rows.append({\n",
        "            \"seed_query\": seed,\n",
        "            \"source_video_id\": df_videos.loc[i, \"video_id\"],\n",
        "            \"video_id\":        df_videos.loc[j, \"video_id\"],\n",
        "            \"title\":           df_videos.loc[j, \"title\"],\n",
        "            \"channel_title\":   df_videos.loc[j, \"channel_title\"],\n",
        "            \"similarity\":      float(sim)\n",
        "        })\n",
        "\n",
        "df_edges = pd.DataFrame(rows).drop_duplicates()\n",
        "# keep edges whose endpoints exist in nodes\n",
        "valid_ids = set(df_videos[\"video_id\"])\n",
        "df_edges = df_edges[\n",
        "    df_edges[\"source_video_id\"].isin(valid_ids) & df_edges[\"video_id\"].isin(valid_ids)\n",
        "].copy()\n",
        "\n",
        "# save both processed and clean versions\n",
        "df_edges.to_csv(\"data/processed/similarity_topk_edges.csv\", index=False)\n",
        "df_edges.to_csv(\"data/clean/edges_clean.csv\", index=False)\n",
        "\n",
        "print(\"Saved edges:\", \"data/clean/edges_clean.csv\", \"rows:\", len(df_edges))\n"
      ],
      "metadata": {
        "id": "auASBtIjqFaq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "VIDEOS_PATH = \"data/clean/videos_clean.csv\"\n",
        "EDGES_PATH  = \"data/clean/edges_clean.csv\"\n",
        "\n",
        "assert os.path.exists(VIDEOS_PATH), f\"Missing file: {VIDEOS_PATH}.\"\n",
        "assert os.path.exists(EDGES_PATH),  f\"Missing file: {EDGES_PATH}.\"\n",
        "\n",
        "df_videos = pd.read_csv(VIDEOS_PATH)\n",
        "df_edges  = pd.read_csv(EDGES_PATH)\n",
        "\n",
        "print(f\"Loaded (CLEAN): {len(df_videos)} videos; {len(df_edges)} edges\")\n",
        "display(df_videos.head(2)); display(df_edges.head(2))\n",
        "\n",
        "# minimal integrity checks (keep visible)\n",
        "print(\"Duplicates by video_id:\", df_videos.duplicated(subset=[\"video_id\"]).sum())\n",
        "print(\"Unique source nodes in edges:\", df_edges[\"source_video_id\"].nunique())\n",
        "print(\"Unique target nodes in edges:\", df_edges[\"video_id\"].nunique())\n"
      ],
      "metadata": {
        "id": "prqFPmrnqIpe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Largest Connected Component size per seed (with soft tab10 colors)\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "\n",
        "# 1) Load CLEAN data (assumes your pipeline already saved these files)\n",
        "VIDEOS_PATH = \"data/clean/videos_clean.csv\"\n",
        "EDGES_PATH  = \"data/clean/edges_clean.csv\"\n",
        "df_videos = pd.read_csv(VIDEOS_PATH)\n",
        "df_edges  = pd.read_csv(EDGES_PATH)\n",
        "\n",
        "# 2) Build an undirected graph (canonicalize edges so (u,v)==(v,u))\n",
        "edges_uv = df_edges[[\"source_video_id\", \"video_id\"]].dropna().astype(str)\n",
        "edges_uv = edges_uv.rename(columns={\"source_video_id\": \"u\", \"video_id\": \"v\"})\n",
        "canon_uv = np.minimum(edges_uv[[\"u\",\"v\"]].to_numpy(), edges_uv[[\"v\",\"u\"]].to_numpy())\n",
        "canon_vu = np.maximum(edges_uv[[\"u\",\"v\"]].to_numpy(), edges_uv[[\"v\",\"u\"]].to_numpy())\n",
        "canon = pd.DataFrame(np.column_stack([canon_uv[:,0], canon_vu[:,1]]), columns=[\"u\",\"v\"]).drop_duplicates()\n",
        "G = nx.from_pandas_edgelist(canon, source=\"u\", target=\"v\", create_using=nx.Graph())\n",
        "\n",
        "# 3) Compute LCC size for each seed (within its own induced subgraph)\n",
        "lcc_sizes = {}\n",
        "for seed in df_videos[\"seed_query\"].dropna().unique():\n",
        "    nodes_seed = set(df_videos.loc[df_videos[\"seed_query\"] == seed, \"video_id\"].astype(str))\n",
        "    H = G.subgraph(nodes_seed).copy()\n",
        "    if H.number_of_nodes() == 0:\n",
        "        lcc_sizes[seed] = 0\n",
        "    else:\n",
        "        comps = sorted(nx.connected_components(H), key=len, reverse=True)\n",
        "        lcc_sizes[seed] = len(comps[0])\n",
        "\n",
        "# 4) Plot with soft tab10 colors (consistent with your other charts)\n",
        "palette = {\n",
        "    \"healthy cooking\":   \"#1f77b4\",  # soft blue\n",
        "    \"beginner guitar\":   \"#ff7f0e\",  # soft orange\n",
        "    \"stretching exercises\": \"#2ca02c\",  # soft green\n",
        "}\n",
        "seeds_order = list(lcc_sizes.keys())\n",
        "values = [lcc_sizes[s] for s in seeds_order]\n",
        "colors = [palette.get(s, \"#1f77b4\") for s in seeds_order]\n",
        "\n",
        "plt.figure(figsize=(9,5))\n",
        "bars = plt.barh(seeds_order, values, color=colors)\n",
        "\n",
        "# annotate values to the right of bars\n",
        "xmax = max(values) if values else 0\n",
        "for bar, val in zip(bars, values):\n",
        "    plt.text(val + max(2, 0.02*xmax), bar.get_y() + bar.get_height()/2,\n",
        "             f\"{val}\", va=\"center\", ha=\"left\")\n",
        "\n",
        "plt.xlabel(\"Number of videos in LCC\")\n",
        "plt.title(\"Largest Connected Component size per seed\")\n",
        "\n",
        "import matplotlib.patches as mpatches\n",
        "\n",
        "# cria manualmente os \"handles\" com as cores e labels corretas\n",
        "legend_handles = [\n",
        "    mpatches.Patch(color=palette[\"healthy cooking\"], label=\"healthy cooking\"),\n",
        "    mpatches.Patch(color=palette[\"beginner guitar\"], label=\"beginner guitar\"),\n",
        "    mpatches.Patch(color=palette[\"stretching exercises\"], label=\"stretching exercises\"),\n",
        "]\n",
        "\n",
        "\n",
        "plt.legend(\n",
        "    handles=legend_handles,\n",
        "    title=\"Seed\",\n",
        "    loc=\"upper left\",\n",
        "    bbox_to_anchor=(1.02, 1)\n",
        ")\n",
        "\n",
        "\n",
        "# add a bit of right margin to prevent clipping\n",
        "plt.xlim(0, xmax + max(10, 0.1*xmax))\n",
        "os.makedirs(\"figures\", exist_ok=True)\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"figures/lcc_sizes.png\", dpi=150, bbox_inches=\"tight\")\n",
        "plt.show()\n",
        "\n",
        "print(\"Saved figure to: figures/lcc_sizes.png\")\n",
        "print(\"LCC sizes:\", lcc_sizes)\n"
      ],
      "metadata": {
        "id": "qsmTMHc29YFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Similarity & Diversity summaries ===\n",
        "# Requires: df_videos (with columns ['video_id','seed_query']), df_edges (['source_video_id','video_id'])\n",
        "# Also assumes SEEDS is defined as the list of your three seeds in desired order.\n",
        "import math, collections, numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "os.makedirs(\"figures\", exist_ok=True)\n",
        "\n",
        "# ---------- Jaccard similarity between seeds (videos) ----------\n",
        "# sets of video_ids by seed\n",
        "by_seed = {s: set(df_videos.loc[df_videos[\"seed_query\"] == s, \"video_id\"]) for s in SEEDS}\n",
        "\n",
        "def jaccard(a, b):\n",
        "    inter = len(a & b)\n",
        "    uni = len(a | b) or 1\n",
        "    return inter / uni\n",
        "\n",
        "J = np.zeros((len(SEEDS), len(SEEDS)), dtype=float)\n",
        "for i, si in enumerate(SEEDS):\n",
        "    for j, sj in enumerate(SEEDS):\n",
        "        J[i, j] = jaccard(by_seed[si], by_seed[sj])\n",
        "\n",
        "plt.figure(figsize=(6, 5))\n",
        "plt.imshow(J, vmin=0, vmax=1, cmap=\"viridis\")\n",
        "plt.colorbar(label=\"Jaccard\")\n",
        "plt.xticks(range(len(SEEDS)), SEEDS, rotation=45, ha=\"right\")\n",
        "plt.yticks(range(len(SEEDS)), SEEDS)\n",
        "for i in range(len(SEEDS)):\n",
        "    for j in range(len(SEEDS)):\n",
        "        plt.text(j, i, f\"{J[i,j]:.2f}\", ha=\"center\", va=\"center\", color=\"w\")\n",
        "plt.title(\"Jaccard similarity between seeds (videos)\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"figures/jaccard_seeds.png\", dpi=150)\n",
        "plt.show()\n",
        "print(\"Saved: figures/jaccard_seeds.png\")\n",
        "\n",
        "# ---------- Diversity by seed (entropy of neighbor seeds reached via edges) ----------\n",
        "# Map each video_id -> its (most frequent) seed label\n",
        "# If there are duplicates in df_videos for a video_id, use the mode of seed_query.\n",
        "seed_per_video = (\n",
        "    df_videos.groupby(\"video_id\")[\"seed_query\"]\n",
        "    .agg(lambda s: s.mode().iloc[0] if not s.mode().empty else \"unknown\")\n",
        "    .to_dict()\n",
        ")\n",
        "\n",
        "# Build, for each seed S, the multiset of neighbor seeds reached from source videos with seed S\n",
        "neighbors_by_seed = {s: [] for s in SEEDS}\n",
        "if {\"source_video_id\", \"video_id\"}.issubset(df_edges.columns):\n",
        "    # keep only edges whose endpoints we can map to seeds\n",
        "    has_src = df_edges[\"source_video_id\"].isin(seed_per_video)\n",
        "    has_dst = df_edges[\"video_id\"].isin(seed_per_video)\n",
        "    e2 = df_edges.loc[has_src & has_dst, [\"source_video_id\", \"video_id\"]].copy()\n",
        "\n",
        "    # For each edge, look at the seed of its source and the seed of its target\n",
        "    src_seeds = e2[\"source_video_id\"].map(seed_per_video)\n",
        "    dst_seeds = e2[\"video_id\"].map(seed_per_video)\n",
        "\n",
        "    for s_src, s_dst in zip(src_seeds, dst_seeds):\n",
        "        if s_src in neighbors_by_seed:\n",
        "            neighbors_by_seed[s_src].append(s_dst)\n",
        "\n",
        "def entropy_normalized(labels_list, universe_size):\n",
        "    \"\"\"Shannon entropy of the label distribution, normalized by log2(universe_size).\"\"\"\n",
        "    cnt = collections.Counter(labels_list)\n",
        "    tot = sum(cnt.values())\n",
        "    if tot == 0:\n",
        "        return 0.0\n",
        "    ps = [c / tot for c in cnt.values() if c > 0]\n",
        "    H = -sum(p * math.log(p, 2) for p in ps)\n",
        "    norm = math.log(max(1, universe_size), 2)\n",
        "    return H / norm if norm > 0 else 0.0\n",
        "\n",
        "K = len(SEEDS)  # normalize by the number of seed categories\n",
        "diversity = {s: entropy_normalized(neighbors_by_seed[s], K) for s in SEEDS}\n",
        "\n",
        "# Use the same soft Tab10-inspired palette you picked elsewhere\n",
        "palette = {\n",
        "    \"healthy cooking\":    \"#1f77b4\",  # soft blue\n",
        "    \"beginner guitar\":    \"#ff7f0e\",  # soft orange\n",
        "    \"stretching exercises\":\"#2ca02c\", # soft green\n",
        "}\n",
        "colors = [palette.get(s, \"#1f77b4\") for s in SEEDS]\n",
        "\n",
        "plt.figure(figsize=(7, 4))\n",
        "plt.bar(range(len(SEEDS)), [diversity[s] for s in SEEDS], color=colors)\n",
        "plt.xticks(range(len(SEEDS)), SEEDS, rotation=45, ha=\"right\")\n",
        "plt.ylabel(\"Normalized diversity (entropy / log2 K)\")\n",
        "plt.title(\"Diversity by seed\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"figures/diversity_by_seed.png\", dpi=150)\n",
        "plt.show()\n",
        "print(\"Saved: figures/diversity_by_seed.png\")\n"
      ],
      "metadata": {
        "id": "J6rCsFUyCkze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Helpers (idempotent if re-run) ---\n",
        "\n",
        "from collections import Counter\n",
        "import math\n",
        "\n",
        "# Map node -> seed label (unknown if missing)\n",
        "seed_by_node = dict(zip(df_videos[\"video_id\"], df_videos[\"seed_query\"]))\n",
        "\n",
        "def normalized_entropy_of_seeds(node_ids):\n",
        "    \"\"\"Shannon entropy of seed labels over node_ids, normalized by log2(K).\"\"\"\n",
        "    labels = [seed_by_node.get(n, \"unknown\") for n in node_ids]\n",
        "    labels = [x for x in labels if x is not None]  # drop Nones\n",
        "    if len(labels) == 0:\n",
        "        return 0.0\n",
        "    c = Counter(labels)\n",
        "    ps = [v/len(labels) for v in c.values()]\n",
        "    H = -sum(p*math.log(p, 2) for p in ps if p > 0)\n",
        "    K = max(1, len(SEEDS))  # number of expected seeds\n",
        "    return H / math.log(K, 2)\n",
        "\n",
        "def nodes_within_k(G, starts, k):\n",
        "    \"\"\"Union of nodes within <=k hops from ANY start node (cumulative).\"\"\"\n",
        "    visited = set(starts)\n",
        "    frontier = set(starts)\n",
        "    for _ in range(k):\n",
        "        nxt = set()\n",
        "        for u in frontier:\n",
        "            nxt.update(G.neighbors(u))\n",
        "        nxt -= visited\n",
        "        visited |= nxt\n",
        "        frontier = nxt\n",
        "        if not frontier:\n",
        "            break\n",
        "    return visited\n",
        "\n",
        "# --- Build series per seed with debug guards ---\n",
        "\n",
        "steps = [0, 1, 2, 3]  # the x-axis you expect\n",
        "\n",
        "# Start nodes present in the graph for each seed\n",
        "by_seed_ids = {s: set(df_videos.loc[df_videos[\"seed_query\"] == s, \"video_id\"]) for s in SEEDS}\n",
        "seed_nodes = {s: sorted([vid for vid in by_seed_ids[s] if vid in G]) for s in SEEDS}\n",
        "\n",
        "# Quick sanity print (kept visible for grading transparency)\n",
        "for s in SEEDS:\n",
        "    print(f\"Seed '{s}': {len(by_seed_ids[s])} videos in table, {len(seed_nodes[s])} present in graph\")\n",
        "\n",
        "series = {s: [] for s in SEEDS}\n",
        "for s in SEEDS:\n",
        "    starts = seed_nodes[s]\n",
        "    if len(starts) == 0:\n",
        "        # nothing to expand from; fill zeros so the plot still renders\n",
        "        series[s] = [0.0 for _ in steps]\n",
        "        continue\n",
        "\n",
        "    # step 0: only the seeds' own nodes\n",
        "    series[s].append(normalized_entropy_of_seeds(starts))\n",
        "\n",
        "    # cumulative expansion\n",
        "    for k in steps[1:]:\n",
        "        nodes_k = nodes_within_k(G, starts, k)\n",
        "        series[s].append(normalized_entropy_of_seeds(nodes_k))\n",
        "\n",
        "# --- Plot ---\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "for s in SEEDS:\n",
        "    plt.plot(steps, series[s], marker=\"o\", label=s)\n",
        "\n",
        "plt.xlabel(\"Step (cumulative)\")\n",
        "plt.ylabel(\"Entropy of clusters\")\n",
        "plt.title(\"Entropy vs Step (cumulative by seed)\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"figures/entropy_vs_step.png\", dpi=150)\n",
        "plt.show()\n",
        "print(\"Saved: figures/entropy_vs_step.png\")\n"
      ],
      "metadata": {
        "id": "XpaafRvBFFrx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Finished\n",
        "\n",
        "Artifacts:\n",
        "- CLEAN nodes: `data/clean/videos_clean.csv`\n",
        "- CLEAN edges: `data/clean/edges_clean.csv`\n",
        "- TF-IDF & similarity: `data/processed/*`\n",
        "- Figures: `figures/*.png`\n",
        "\n",
        "Repro tips:\n",
        "- To rebuild from scratch, set `USE_API=True` and rerun from the top.\n",
        "- To keep runs deterministic, do not change `TOPK_PER_SEED` and `RANDOM_STATE`.\n"
      ],
      "metadata": {
        "id": "D6lwtsmoqbcf"
      }
    }
  ]
}